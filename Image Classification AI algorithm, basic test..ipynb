{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3209eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b69af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d221e632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 14:22:46.826165: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-17 14:22:47.467618: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the number of classes in your dataset\n",
    "num_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a660df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Set the path to the extracted dataset folder\n",
    "dataset_folder = '/home/amit/FoodImage'\n",
    "\n",
    "# Set the split ratio for training and testing\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "# Create directories for train and test sets\n",
    "train_dir = '/home/amit/FoodImage_train'\n",
    "test_dir = '/home/amit/FoodImage_test'\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over subfolders in the dataset folder\n",
    "for class_folder in os.listdir(dataset_folder):\n",
    "    class_path = os.path.join(dataset_folder, class_folder)\n",
    "    if os.path.isdir(class_path):\n",
    "        # Create subdirectories in train and test directories\n",
    "        train_class_dir = os.path.join(train_dir, class_folder)\n",
    "        test_class_dir = os.path.join(test_dir, class_folder)\n",
    "        os.makedirs(train_class_dir, exist_ok=True)\n",
    "        os.makedirs(test_class_dir, exist_ok=True)\n",
    "\n",
    "        # Get the list of images in the current class folder\n",
    "        images = os.listdir(class_path)\n",
    "        random.shuffle(images)\n",
    "\n",
    "        # Calculate the number of images for train and test sets\n",
    "        num_train = int(train_ratio * len(images))\n",
    "        num_test = len(images) - num_train\n",
    "\n",
    "        # Move images to train and test subdirectories\n",
    "        train_images = images[:num_train]\n",
    "        test_images = images[num_train:]\n",
    "\n",
    "        for image in train_images:\n",
    "            src = os.path.join(class_path, image)\n",
    "            dst = os.path.join(train_class_dir, image)\n",
    "            shutil.move(src, dst)\n",
    "\n",
    "        for image in test_images:\n",
    "            src = os.path.join(class_path, image)\n",
    "            dst = os.path.join(test_class_dir, image)\n",
    "            shutil.move(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce1c66f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters for preprocessing and data augmentation\n",
    "image_size = (224, 224)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0367731e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 396 images belonging to 6 classes.\n",
      "Found 101 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Use ImageDataGenerator to load and preprocess the images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Create data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05aab414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 14:23:33.032546: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-17 14:23:33.093616: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "\n",
    "# Bypass SSL certificate verification\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Build the model architecture\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f37e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e9799ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 14:23:54.946729: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - ETA: 0s - loss: 1.7056 - accuracy: 0.3131"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 14:24:03.677802: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 11s 700ms/step - loss: 1.7056 - accuracy: 0.3131 - val_loss: 1.1592 - val_accuracy: 0.5248\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 8s 618ms/step - loss: 0.8466 - accuracy: 0.7551 - val_loss: 0.7470 - val_accuracy: 0.7327\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 8s 628ms/step - loss: 0.5113 - accuracy: 0.8965 - val_loss: 0.5718 - val_accuracy: 0.8317\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 8s 646ms/step - loss: 0.3532 - accuracy: 0.9318 - val_loss: 0.4845 - val_accuracy: 0.8614\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 8s 619ms/step - loss: 0.2709 - accuracy: 0.9545 - val_loss: 0.4337 - val_accuracy: 0.8812\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 9s 653ms/step - loss: 0.2191 - accuracy: 0.9646 - val_loss: 0.4054 - val_accuracy: 0.8614\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 8s 642ms/step - loss: 0.1820 - accuracy: 0.9924 - val_loss: 0.3756 - val_accuracy: 0.8713\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 8s 614ms/step - loss: 0.1530 - accuracy: 0.9899 - val_loss: 0.3675 - val_accuracy: 0.8713\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 9s 647ms/step - loss: 0.1317 - accuracy: 0.9924 - val_loss: 0.3522 - val_accuracy: 0.8812\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 9s 689ms/step - loss: 0.1163 - accuracy: 0.9949 - val_loss: 0.3371 - val_accuracy: 0.8812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa59079bcd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 10\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=num_epochs,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_generator)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "022488bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 14:25:29.267289: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 379ms/step - loss: 0.3371 - accuracy: 0.8812\n",
      "Test Loss: 0.33706218004226685\n",
      "Test Accuracy: 0.8811880946159363\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415664b3",
   "metadata": {},
   "source": [
    "I used the MobileNetV2 pre-trained model as the base model, with additional layers added on top for classification. \n",
    "\n",
    "The code demonstrates the training, evaluation, and testing process using the provided datasets.\n",
    "\n",
    "A test loss of 0.337 indicates that the model's predictions are relatively close to the true labels on average. Lower values of test loss are desirable, indicating better performance.\n",
    "\n",
    "A test accuracy of 0.881 suggests that the model is correctly classifying around 88.1% of the food images in the test dataset. Higher values of test accuracy indicate better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721ae031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model with external images\n",
    "# Load and preprocess the external images\n",
    "external_images_dir = 'path/to/external/images'\n",
    "external_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "external_generator = external_datagen.flow_from_directory(\n",
    "    external_images_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=1,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d4de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the external images\n",
    "predictions = model.predict(external_generator)\n",
    "predicted_classes = tf.argmax(predictions, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1215b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the predicted classes\n",
    "class_names = train_generator.class_indices\n",
    "for i, class_index in enumerate(predicted_classes):\n",
    "    class_name = list(class_names.keys())[list(class_names.values()).index(class_index)]\n",
    "    print(f\"Image {i+1} predicted class:\", class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338cdee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
